{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa8868cd",
   "metadata": {},
   "source": [
    "# First Session of Stochastic Modelling\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/guglielmopadula/StochasticModelling2022-2023/blob/main/FirstSession.ipynb)\n",
    "\n",
    "## Part 1: A very fast recap of Probability\n",
    "\n",
    "From Wikipedia:\n",
    "\n",
    "The **probability** of an event is a number that indicates how likely the event is to occur.\n",
    "\n",
    "### Basic rules of probability:\n",
    "\n",
    "$$P(A\\cup B)+P(A\\cap B)=P(A)+P(B) \\quad \\forall A,B \\in \\Omega$$\n",
    "\n",
    "$$0 \\le P(A)\\le 1 \\quad \\forall A \\in \\Omega$$ \n",
    "\n",
    "$$P(A|B)P(B)=P(A\\cap B) \\quad \\forall A,B \\in \\Omega$$ (Bayes law)\n",
    "\n",
    "$$P(A)=P(A|B)P(B)+P(A|B^{C})P(B^{C}) \\quad \\forall A,B \\in \\Omega$$ (law of total probability)\n",
    "\n",
    "$$P(B^{C})=1-P(B) \\quad \\forall B\\in \\Omega$$\n",
    "\n",
    "If $A$ and $B$ are independent we have $$P(A \\cap B)= P(A)P(B) \\quad \\forall A,B \\in \\Omega$$\n",
    "\n",
    "### A realistic exercise\n",
    "\n",
    "Let's do a very basic exercise (which I actually did in the last year):\n",
    "\n",
    "It is known from the academic year 2020-2021 that a student who does his Stochastic Modelling homeworks has a chance of 90 percent to get a very good grade (between $27$ and $30$); but the chance drops to 75 percent if he doesn't do the homeworks.\n",
    "Guglielmo has been very busy with other courses and figures that he has only a 69 percent chance of doing the homeworks.\n",
    "What are his chance of not getting a very good grade in the course?\n",
    "\n",
    "Answer:\n",
    "There are two important events under discussion. Let us name them.\n",
    "\n",
    "$E$ : doing homeworks.\n",
    "\n",
    "$F$ : getting a very good grade.\n",
    "\n",
    "We know that $$P(F|E)=0.9$$, $$P(F|E^{C})=0.75$$ and $$P(E)=0.69$$\n",
    "\n",
    "The solution is to use the ..... you tell me, question time!!!\n",
    "\n",
    "## Part 2: A very fast recap of Random Variables\n",
    "\n",
    "- A random variable is function $$X: \\Omega \\rightarrow \\mathbb{R}$$ \n",
    "- A random variable is characterized by it's cumulative density function $F(x)=P(X\\le x)$.\n",
    "- A discrete random variable has a countable support and it is characterized by $P(X=x)=F(x)-F(X=\\max_{y\\in X|F(y)< F(x)} y)$.\n",
    "- A continous random variable has a noncountable support and is characterized by $f(x)=\\frac{dF}{dx}$\n",
    "\n",
    "The most important properties of a random variable are the moments\n",
    "- non central moments: $E[X^{k}]=\\int_{Im(X)}y^{k}f(y)dy$ if the variable is continuous or $E[X^{k}]=\\sum_{y \\in Im(x)}y^{k}f(y)$ if the variable is discrete\n",
    "- central moments: $E[(X-E[X])^{k}]=\\int_{Im(X)}(y-E[X])^{k}f(y)dy$ if the variable is continuous or $E[X^{k}]=\\sum_{y \\in Im(x)}(y-E[X])^{k}f(y)$ if the variable is discrete\n",
    "\n",
    "Examples of r.v:\n",
    "- continuous: Gaussian, Exponential, Beta, UniformContinous\n",
    "- discrete: Bernoulli, Binomial, Poisson\n",
    "\n",
    "\n",
    "Properties of mean and variance:\n",
    "$$E[aX+bY]=aE[X]+bE[Y]$$\n",
    "$$Var[aX]=a^{2}Var[X]$$\n",
    "$$Var[X+Y]=Var[X]+Var[Y]+2Cov(X,Y)$$\n",
    "\n",
    "Some random variables are identically distributed if they have the same cdf/pdf.\n",
    "There are two very important theorems in probability. Let's assume that we have a set of i.i.d  random variables $X_{i}$ with finite mean and variance, then:\n",
    "- Central limit theorem: $$\\frac{\\sum\\limits_{i=1}^{n} X_{i}-nE[X]}{\\sqrt{nVar[X]}}\\rightarrow Normal(0,1)$$\n",
    "- Law of large numbers: $$\\frac{\\sum\\limits_{i=1}^{n} X_{i}}{n}\\rightarrow E[X]$$\n",
    "\n",
    "## A coin tossing\n",
    "Let's suppose we want to see if a coin is balanced. We may use random variables. We may toss a coin a lot of times and assign to a random variable the value 1 is we get head and the value 0 if we get tail. So we get a binary variable, which is usually called Bernoulli random variable. \n",
    "$$X=\\begin{cases} 1 \\text{ with probability } p \\\\\n",
    "0 \\text{ with probability } 1-p \\end{cases}$$\n",
    "\n",
    "An important property of a Bernoulli random variable is that $E[X]=0*(1-p)+1*p=p$\n",
    "\n",
    "Our coin is balanced if and only if we have $p=0.5$.\n",
    "\n",
    "As tossing a coin is slow (and I only have one hour) we are going to simulate the tosses using scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f785fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tail\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import bernoulli #basic python importing\n",
    "from tqdm import trange #Very useful function that you probably don't know\n",
    "class TossingMachine():\n",
    "    def __init__(self):\n",
    "        self.p=0.5\n",
    "        self.dist=bernoulli\n",
    "    \n",
    "    def toss(self):\n",
    "        a=self.dist.rvs(self.p)\n",
    "        if a==1:\n",
    "            return \"Head\"\n",
    "        else:\n",
    "            return \"Tail\"\n",
    "\n",
    "tossing_machine=TossingMachine()\n",
    "print(tossing_machine.toss())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8adad7e",
   "metadata": {},
   "source": [
    "To see if our virtual coin is balanced or not we may toss a lot of times and then calculate the sample avarage. \n",
    "The sample average will approximate our probability $p$ because of the law of large numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a9e1b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100000/100000 [00:02<00:00, 40823.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X=[] #inizialization of the list\n",
    "for i in trange(100000):\n",
    "    tmp=tossing_machine.toss()\n",
    "    if tmp==\"Head\":\n",
    "        X.append(1)\n",
    "    else:\n",
    "        X.append(0)\n",
    "\n",
    "print(sum(X)/100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda3db64",
   "metadata": {},
   "source": [
    "We got a value near $0.5$. So we are happy :-) ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b6224f",
   "metadata": {},
   "source": [
    "## The queen of all r.v: the Gaussian R.V. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08afd764",
   "metadata": {},
   "source": [
    "The Gaussian distribution is characterized by it's mean $\\mu$ and it's variance $\\sigma^{2}$.\n",
    "It has the following pdf\n",
    "$$\n",
    "f(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-(\\frac{x-\\mu}{\\sigma})^{2}}$$\n",
    "The parameter $\\sigma$ is called standard deviation. \n",
    "The Gaussian distribution is particulary important because of the following two properties:\n",
    "- it is the limit distribution of the central limit theorem\n",
    "- it is the only distribution with finite variance such that all linear combinations of **independent** random variables from it's distribution have it's distribution:\n",
    "$$ X_{i}\\sim N(\\mu_{i},\\sigma_{i}^{2})$$ \n",
    "$$\\sum_{i=1}^{n} a_{i}X_{i}\\sim N(\\sum\\limits_{i=1}^{n} a_{i}\\mu_{i},\\sum\\limits_{i=1}^{n} a_{i}^{2}\\sigma_{i}^{2})$$\n",
    "This two properties are strongly linked with each other, for a proof of this I invite to follow the course of Information Theory.\n",
    "\n",
    "Let's now look at scipy stats function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "019bf0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(X<=0) is,  0.4012936743170763\n",
      "Variance of X is 16.0\n",
      "Mean of X is 1.0\n",
      "f(0) is 0.09666702920071232\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm #normal random variable\n",
    "distribution=norm(1,4) #mean=1, standard deviation=1,not variance!!!\n",
    "print(\"P(X<=0) is, \",distribution.cdf(0))\n",
    "print(\"Variance of X is\", distribution.var())\n",
    "print(\"Mean of X is\", distribution.mean())\n",
    "print(\"f(0) is\",distribution.pdf(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb70331d",
   "metadata": {},
   "source": [
    "Before we say goodbye, one last question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff2d02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
